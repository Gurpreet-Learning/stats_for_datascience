{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Regression And Prediction: Stepwise Linear Regression- Page 238\n",
    "    Contains Functions:\n",
    "       Stepwise Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import math\n",
    "import pylab\n",
    "import random\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "    ![Model Formula](https://wikimedia.org/api/rest_v1/media/math/render/svg/704b31aa61dfc93d672f15bf02aa6d168be49643)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.150228</td>\n",
       "      <td>-0.647258</td>\n",
       "      <td>-0.258421</td>\n",
       "      <td>0.749926</td>\n",
       "      <td>0.186117</td>\n",
       "      <td>0.695557</td>\n",
       "      <td>-1.080732</td>\n",
       "      <td>-0.227240</td>\n",
       "      <td>-2.589893</td>\n",
       "      <td>0.269304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859401</td>\n",
       "      <td>1.107162</td>\n",
       "      <td>0.041735</td>\n",
       "      <td>0.565340</td>\n",
       "      <td>1.015892</td>\n",
       "      <td>-2.128823</td>\n",
       "      <td>2.024022</td>\n",
       "      <td>-0.333231</td>\n",
       "      <td>-0.204844</td>\n",
       "      <td>160.636216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.193624</td>\n",
       "      <td>0.637780</td>\n",
       "      <td>-0.222977</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.022765</td>\n",
       "      <td>-0.095462</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>0.402595</td>\n",
       "      <td>-0.560716</td>\n",
       "      <td>0.632586</td>\n",
       "      <td>...</td>\n",
       "      <td>1.689768</td>\n",
       "      <td>-0.203603</td>\n",
       "      <td>0.299804</td>\n",
       "      <td>0.495515</td>\n",
       "      <td>-2.020823</td>\n",
       "      <td>-0.243168</td>\n",
       "      <td>-0.264210</td>\n",
       "      <td>1.670538</td>\n",
       "      <td>1.882344</td>\n",
       "      <td>-190.250377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.377882</td>\n",
       "      <td>0.757898</td>\n",
       "      <td>0.199256</td>\n",
       "      <td>-1.187256</td>\n",
       "      <td>0.185342</td>\n",
       "      <td>-0.091670</td>\n",
       "      <td>0.302742</td>\n",
       "      <td>-1.544767</td>\n",
       "      <td>0.205811</td>\n",
       "      <td>-0.841876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514926</td>\n",
       "      <td>0.812424</td>\n",
       "      <td>1.153086</td>\n",
       "      <td>-0.204190</td>\n",
       "      <td>-0.744905</td>\n",
       "      <td>-0.265578</td>\n",
       "      <td>-0.711802</td>\n",
       "      <td>0.085286</td>\n",
       "      <td>2.074812</td>\n",
       "      <td>-15.315213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.913615</td>\n",
       "      <td>-0.132294</td>\n",
       "      <td>-0.739062</td>\n",
       "      <td>-1.600399</td>\n",
       "      <td>-0.183899</td>\n",
       "      <td>-0.361266</td>\n",
       "      <td>-0.459224</td>\n",
       "      <td>-0.118342</td>\n",
       "      <td>0.056168</td>\n",
       "      <td>1.343363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743626</td>\n",
       "      <td>1.974761</td>\n",
       "      <td>-0.718708</td>\n",
       "      <td>-0.619913</td>\n",
       "      <td>0.618423</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>-0.304795</td>\n",
       "      <td>-0.805131</td>\n",
       "      <td>0.231316</td>\n",
       "      <td>37.663762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.836089</td>\n",
       "      <td>-0.944510</td>\n",
       "      <td>-2.638461</td>\n",
       "      <td>0.393566</td>\n",
       "      <td>1.713522</td>\n",
       "      <td>1.028408</td>\n",
       "      <td>1.549729</td>\n",
       "      <td>0.685787</td>\n",
       "      <td>2.459642</td>\n",
       "      <td>0.607970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318129</td>\n",
       "      <td>0.110768</td>\n",
       "      <td>-0.127362</td>\n",
       "      <td>0.416896</td>\n",
       "      <td>-1.572623</td>\n",
       "      <td>0.925379</td>\n",
       "      <td>0.248693</td>\n",
       "      <td>-0.884124</td>\n",
       "      <td>0.853936</td>\n",
       "      <td>139.049296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -1.150228 -0.647258 -0.258421  0.749926  0.186117  0.695557 -1.080732   \n",
       "1  1.193624  0.637780 -0.222977  0.796864  0.022765 -0.095462 -0.487500   \n",
       "2 -2.377882  0.757898  0.199256 -1.187256  0.185342 -0.091670  0.302742   \n",
       "3  0.913615 -0.132294 -0.739062 -1.600399 -0.183899 -0.361266 -0.459224   \n",
       "4  1.836089 -0.944510 -2.638461  0.393566  1.713522  1.028408  1.549729   \n",
       "\n",
       "          7         8         9  ...        21        22        23        24  \\\n",
       "0 -0.227240 -2.589893  0.269304  ...  0.859401  1.107162  0.041735  0.565340   \n",
       "1  0.402595 -0.560716  0.632586  ...  1.689768 -0.203603  0.299804  0.495515   \n",
       "2 -1.544767  0.205811 -0.841876  ... -0.514926  0.812424  1.153086 -0.204190   \n",
       "3 -0.118342  0.056168  1.343363  ...  0.743626  1.974761 -0.718708 -0.619913   \n",
       "4  0.685787  2.459642  0.607970  ...  0.318129  0.110768 -0.127362  0.416896   \n",
       "\n",
       "         25        26        27        28        29           Y  \n",
       "0  1.015892 -2.128823  2.024022 -0.333231 -0.204844  160.636216  \n",
       "1 -2.020823 -0.243168 -0.264210  1.670538  1.882344 -190.250377  \n",
       "2 -0.744905 -0.265578 -0.711802  0.085286  2.074812  -15.315213  \n",
       "3  0.618423  0.793103 -0.304795 -0.805131  0.231316   37.663762  \n",
       "4 -1.572623  0.925379  0.248693 -0.884124  0.853936  139.049296  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_size=30 #number of features\n",
    "def create_linear_data(n_samples=10000,f=features_size):   \n",
    "    # Get regression data from scikit-learn\n",
    "    x,y = datasets.make_regression(n_samples=n_samples,noise=80, n_features=f)\n",
    "    x=pd.DataFrame(x)\n",
    "    y=pd.DataFrame(y,columns=['Y'])\n",
    "    df = pd.concat([x, y],axis = 1)\n",
    "    return df\n",
    "\n",
    "df = create_linear_data()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size: 6700 Samples, Test Data Size: 3300 Samples.\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(columns=['Y'],axis=1,inplace=False)\n",
    "y= df['Y']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33)\n",
    "print(f'Train Data Size: {len(x_train)} Samples, Test Data Size: {len(x_test)} Samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Linear Model Object Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create linear model object\n",
    "class linear_model:\n",
    "    def __init__(self):\n",
    "        self._beta_l = []\n",
    "        self.y_p = []\n",
    "        self.features= []\n",
    "        \n",
    "    def __get_beta(self,x,y):\n",
    "        for f in self.features:\n",
    "            x_sub = np.array(x[f])\n",
    "            \n",
    "            n = len(x_sub)\n",
    "            x_b = x_sub.mean()\n",
    "            y_b = y.mean()\n",
    "            nume = 0  #numerator of the formula\n",
    "            denom = 0 #denominator of the formula\n",
    "            for i in range(0,n):\n",
    "                nume += (x_sub[i]-x_b)*(y[i]-y_b)  #summation of numerator\n",
    "                denom += (x_sub[i]-x_b)**2 #summation of denominator\n",
    "\n",
    "            beta = nume/denom  #divide\n",
    "            self._beta_l.append(beta) #append beta\n",
    "                               \n",
    "    def fit(self,x,y):\n",
    "        y= np.array(y)\n",
    "        self.features = list(x.columns.values.tolist()) #get list of features\n",
    "        self.__get_beta(x,y)         \n",
    "        y_temp = []\n",
    "        y_p = []\n",
    "        for f_i,f in enumerate(self.features):\n",
    "            x_sub = np.array(x[f])\n",
    "            y_sub = []\n",
    "            for i in range(0,len(x_sub)):\n",
    "                y_i = self._beta_l[f_i]*x_sub[i]\n",
    "                y_sub.append(y_i)\n",
    "            y_temp.append(y_sub)\n",
    "        for i in range(0,len(y)):\n",
    "            _sum = 0\n",
    "            for f in self.features:\n",
    "                _sum+=y_temp[f_i][i]\n",
    "            self.y_p.append(_sum)\n",
    "                               \n",
    "    def predict(self,x_test):\n",
    "        y_pred = []\n",
    "        test_features = list(x_test.columns.values.tolist()) #get list of features\n",
    "        x_test= np.array(x_test)\n",
    "        #test features should be equal to model features\n",
    "        if len(test_features) == len(self.features):\n",
    "            x_n = len(x_test)\n",
    "            for x_i in range(x_n):\n",
    "                y_i = 0\n",
    "                for f_i,f in enumerate(test_features):\n",
    "                    y_i += self._beta_l[f_i]*x_test[x_i][f_i]\n",
    "                y_pred.append(y_i)\n",
    "            \n",
    "            return np.array(y_pred)\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "# Train Model                               \n",
    "model = linear_model()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with R Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared: 0.8312549234762069\n"
     ]
    }
   ],
   "source": [
    "def get_rsquared(y,y_f):\n",
    "    #compute total sum of squares\n",
    "    ss_tot = 0\n",
    "    y = np.array(y)\n",
    "    y_f = np.array(y_f)\n",
    "    y_b = y.mean()\n",
    "    for i in range(0,len(y)):\n",
    "        ss_tot+=(y[i]-y_b)**2\n",
    "    #compute residual sum of squares\n",
    "    ss_res = 0\n",
    "    for i in range(0,len(y)):\n",
    "        ss_res += (y[i]-y_f[i])**2\n",
    "    \n",
    "    return 1-(ss_res/ss_tot)\n",
    "\n",
    "r_squared = get_rsquared(y_test,y_pred)\n",
    "print(f'R Squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 81.49520977166252\n"
     ]
    }
   ],
   "source": [
    "def get_rmse(y,y_f):\n",
    "    '''\n",
    "        params: y = actual values, y_f = predicted values\n",
    "    '''\n",
    "    _se=0\n",
    "    y = np.array(y)\n",
    "    y_f = np.array(y_f)\n",
    "    for i in range(0,len(y_f)):\n",
    "        _se += (y[i]-y_f[i])**2\n",
    "    rmse = math.sqrt(_se/len(y))\n",
    "    return rmse\n",
    "\n",
    "rmse = get_rmse(y_test,y_pred)\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Stepwise Regression Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping feauture: 27, Percent Change: 0.01229246523467293 , RMSE: 81.49452213511678\n",
      "Dropping feauture: 24, Percent Change: 0.2504170843492308 , RMSE: 82.20510385867695\n",
      "Dropping feauture: 21, Percent Change: 0.35497813510475035 , RMSE: 82.10409251388421\n",
      "Dropping feauture: 19, Percent Change: 0.0007562972163681462 , RMSE: 82.08263327409574\n",
      "Dropping feauture: 15, Percent Change: 0.5186821532159513 , RMSE: 81.91703067549797\n",
      "Dropping feauture: 12, Percent Change: 1.5266260703905366e-05 , RMSE: 81.91714115984522\n",
      "Dropping feauture: 9, Percent Change: 0.4325919468048653 , RMSE: 81.91697358652897\n",
      "Dropping feauture: 7, Percent Change: 0.0019143160112033437 , RMSE: 81.91555473753654\n",
      "Dropping feauture: 4, Percent Change: 0.00017722278488857847 , RMSE: 81.90275678795679\n",
      "Dropping feauture: 2, Percent Change: 0.040759705068031823 , RMSE: 81.68237268152592\n",
      "RMSE Final: 81.68237268152592\n"
     ]
    }
   ],
   "source": [
    "# use backward method\n",
    "def stepwise_regression(x_train,x_test,y_train,y_test):\n",
    "    '''\n",
    "        Will gradually drop features until lowest possible rmse can be attained.\n",
    "    '''\n",
    "    features = list(x_train.columns.values.tolist())\n",
    "    n=len(features)\n",
    "    rmse_l = []\n",
    "    r2_l = []\n",
    "    to_drop = []\n",
    "    p_change_l = [0]\n",
    "    model_l = []\n",
    "    for s_i in range(n-1,-1,-1):\n",
    "        if s_i == n-1:\n",
    "            drop_n = [s_i]\n",
    "        else:\n",
    "            drop_n = [s_i]+to_drop\n",
    "        x_train_sub = x_train.drop(columns=drop_n,inplace=False)\n",
    "        x_test_sub = x_test.drop(columns=drop_n,inplace=False)\n",
    "        model = linear_model()\n",
    "        model.fit(x_train_sub,y_train)\n",
    "        y_pred = model.predict(x_test_sub)\n",
    "        _rmse = get_rmse(y_test,y_pred)\n",
    "        rmse_l.append(_rmse)\n",
    "        if s_i < n-1:\n",
    "            p_change = (rmse_l[n-s_i-2]-rmse_l[n-s_i-1])/rmse_l[n-s_i-1]  # compute for p change\n",
    "            p_change_l.append(p_change)\n",
    "            \n",
    "            if p_change_l[n-s_i-1] > p_change_l[n-s_i-2]: # check if percent change is higher\n",
    "                if rmse_l[n-s_i-1] < rmse_l[n-s_i-2]: #check if rmse is lower\n",
    "                    to_drop.append(s_i) #if all conditions passed drop the column\n",
    "                    print(f'Dropping feauture: {s_i}, Percent Change: {p_change} , RMSE: {_rmse}')\n",
    "    \n",
    "    return to_drop\n",
    "     \n",
    "\n",
    "to_drop = stepwise_regression(x_train,x_test,y_train,y_test)\n",
    "x_train_sub = x_train.drop(columns=to_drop,inplace=False)\n",
    "x_test_sub = x_test.drop(columns=to_drop,inplace=False)\n",
    "model = linear_model()\n",
    "model.fit(x_train_sub,y_train)\n",
    "y_pred = model.predict(x_test_sub)\n",
    "_rmse = get_rmse(y_test,y_pred)\n",
    "print(f'RMSE Final: {_rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
